{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e122f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ad3a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset sintético (reemplazar con dataset real en producción)\n",
    "rng = np.random.default_rng(42)\n",
    "n = 500\n",
    "df = pd.DataFrame({\n",
    "    'tiempo_contrato_meses': rng.integers(0, 36, size=n),\n",
    "    'retrasos_pago': rng.integers(0, 6, size=n),\n",
    "    'uso_mensual': rng.normal(12, 4, size=n).clip(0),\n",
    "    'plan': rng.choice(['Basic','Standard','Premium'], size=n)\n",
    "})\n",
    "# Regla para probabilidad de churn\n",
    "z = -1.0 + 0.08*df['retrasos_pago'] - 0.03*df['tiempo_contrato_meses'] - 0.02*df['uso_mensual'] + df['plan'].map({'Basic':0.15,'Standard':0.10,'Premium':0.05})\n",
    "p = 1/(1+np.exp(-z))\n",
    "df['churn'] = (p >= 0.5).astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025532f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot del plan\n",
    "df_ml = pd.get_dummies(df, columns=['plan'], drop_first=True)\n",
    "X = df_ml.drop(columns=['churn'])\n",
    "y = df_ml['churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline: escalado + regresión logística\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "print(classification_report(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a03be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar artefactos\n",
    "joblib.dump(pipe, 'churn_pipeline.pkl')\n",
    "joblib.dump(list(X.columns), 'feature_names.pkl')\n",
    "print('Artefactos guardados: churn_pipeline.pkl, feature_names.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0b896",
   "metadata": {},
   "source": [
    "## Contrato de integración (JSON)\n",
    "Entrada:\n",
    "{\n",
    "\"tiempo_contrato_meses\": 12,\n",
    "\"retrasos_pago\": 2,\n",
    "\"uso_mensual\": 14.5,\n",
    "\"plan\": \"Premium\"\n",
    "}\n",
    "\n",
    "Salida:\n",
    "{ \"prevision\": \"Va a cancelar\", \"probabilidad\": 0.81 }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36398f19",
   "metadata": {},
   "source": [
    "## Métricas del modelo (Accuracy, Precision, Recall, F1)\n",
    "Este bloque calcula métricas de clasificación para el modelo entrenado y muestra el reporte de clasificación y la matriz de confusión. Asegúrate de que existan las variables `model`, `X_test` y `y_test` (producidas por tu pipeline de entrenamiento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9490a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas del modelo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "# Verificaciones mínimas de variables requeridas\n",
    "try:\n",
    "    _ = (model, X_test, y_test)\n",
    "except NameError as e:\n",
    "    raise NameError(\"Variables esperadas no existen: defina 'model', 'X_test', 'y_test' antes de ejecutar métricas.\") from e\n",
    "\n",
    "# Predicción del conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Métricas agregadas (weighted para evitar errores si las etiquetas no son binarias 0/1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (weighted): {precision:.4f}\")\n",
    "print(f\"Recall (weighted): {recall:.4f}\")\n",
    "print(f\"F1-score (weighted): {f1:.4f}\")\n",
    "\n",
    "# Reporte detallado por clase\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
